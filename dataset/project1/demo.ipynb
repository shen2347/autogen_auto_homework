{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 10000\n",
      "\n",
      "Keys in each entry: \n",
      "business_id, date, review_id, stars, text, type, user_id, cool, useful, funny\n",
      "\n",
      "First entry: \n",
      "{'business_id': '9yKzy9PApeiPPOUJEtnvkg',\n",
      " 'cool': '2',\n",
      " 'date': '2011-01-26',\n",
      " 'funny': '0',\n",
      " 'review_id': 'fWKvX83p0-ka4JS3dc6E5A',\n",
      " 'stars': '5',\n",
      " 'text': 'My wife took me here on my birthday for breakfast and it was '\n",
      "         'excellent.  The weather was perfect which made sitting outside '\n",
      "         'overlooking their grounds an absolute pleasure.  Our waitress was '\n",
      "         'excellent and our food arrived quickly on the semi-busy Saturday '\n",
      "         'morning.  It looked like the place fills up pretty quickly so the '\n",
      "         'earlier you get here the better.\\n'\n",
      "         '\\n'\n",
      "         'Do yourself a favor and get their Bloody Mary.  It was phenomenal '\n",
      "         \"and simply the best I've ever had.  I'm pretty sure they only use \"\n",
      "         'ingredients from their garden and blend them fresh when you order '\n",
      "         'it.  It was amazing.\\n'\n",
      "         '\\n'\n",
      "         'While EVERYTHING on the menu looks excellent, I had the white '\n",
      "         'truffle scrambled eggs vegetable skillet and it was tasty and '\n",
      "         'delicious.  It came with 2 pieces of their griddled bread with was '\n",
      "         'amazing and it absolutely made the meal complete.  It was the best '\n",
      "         '\"toast\" I\\'ve ever had.\\n'\n",
      "         '\\n'\n",
      "         \"Anyway, I can't wait to go back!\",\n",
      " 'type': 'review',\n",
      " 'useful': '5',\n",
      " 'user_id': 'rLtl8ZkDX5vH5nAx9C3q5Q'}\n"
     ]
    }
   ],
   "source": [
    "# load the data file\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/yelp.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# show some basic info\n",
    "print('Number of reviews:', len(data))\n",
    "print()\n",
    "\n",
    "print('Keys in each entry: ')\n",
    "print(', '.join(data[0].keys()))\n",
    "print('')\n",
    "\n",
    "print('First entry: ')\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique business ids: 4174\n"
     ]
    }
   ],
   "source": [
    "# count number of unique business ids in this data set\n",
    "business_ids = [entry['business_id'] for entry in data]\n",
    "unique_business_ids = set(business_ids)\n",
    "\n",
    "print('Number of unique business ids:', len(unique_business_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('My wife took me here on my birthday for breakfast and it was excellent.  The '\n",
      " 'weather was perfect which made sitting outside overlooking their grounds an '\n",
      " 'absolute pleasure.  Our waitress was excellent and our food arrived quickly '\n",
      " 'on the semi-busy Saturday morning.  It looked like the place fills up pretty '\n",
      " 'quickly so the earlier you get here the better.\\n'\n",
      " '\\n'\n",
      " 'Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply '\n",
      " \"the best I've ever had.  I'm pretty sure they only use ingredients from \"\n",
      " 'their garden and blend them fresh when you order it.  It was amazing.\\n'\n",
      " '\\n'\n",
      " 'While EVERYTHING on the menu looks excellent, I had the white truffle '\n",
      " 'scrambled eggs vegetable skillet and it was tasty and delicious.  It came '\n",
      " 'with 2 pieces of their griddled bread with was amazing and it absolutely '\n",
      " 'made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n'\n",
      " '\\n'\n",
      " \"Anyway, I can't wait to go back!\")\n",
      "\n",
      "Number of tokens:  175\n",
      "['My',\n",
      " 'wife',\n",
      " 'took',\n",
      " 'me',\n",
      " 'here',\n",
      " 'on',\n",
      " 'my',\n",
      " 'birthday',\n",
      " 'for',\n",
      " 'breakfast',\n",
      " 'and',\n",
      " 'it',\n",
      " 'was',\n",
      " 'excellent',\n",
      " '.',\n",
      " 'The',\n",
      " 'weather',\n",
      " 'was',\n",
      " 'perfect',\n",
      " 'which',\n",
      " 'made',\n",
      " 'sitting',\n",
      " 'outside',\n",
      " 'overlooking',\n",
      " 'their',\n",
      " 'grounds',\n",
      " 'an',\n",
      " 'absolute',\n",
      " 'pleasure',\n",
      " '.',\n",
      " 'Our',\n",
      " 'waitress',\n",
      " 'was',\n",
      " 'excellent',\n",
      " 'and',\n",
      " 'our',\n",
      " 'food',\n",
      " 'arrived',\n",
      " 'quickly',\n",
      " 'on',\n",
      " 'the',\n",
      " 'semi-busy',\n",
      " 'Saturday',\n",
      " 'morning',\n",
      " '.',\n",
      " 'It',\n",
      " 'looked',\n",
      " 'like',\n",
      " 'the',\n",
      " 'place',\n",
      " 'fills',\n",
      " 'up',\n",
      " 'pretty',\n",
      " 'quickly',\n",
      " 'so',\n",
      " 'the',\n",
      " 'earlier',\n",
      " 'you',\n",
      " 'get',\n",
      " 'here',\n",
      " 'the',\n",
      " 'better',\n",
      " '.',\n",
      " 'Do',\n",
      " 'yourself',\n",
      " 'a',\n",
      " 'favor',\n",
      " 'and',\n",
      " 'get',\n",
      " 'their',\n",
      " 'Bloody',\n",
      " 'Mary',\n",
      " '.',\n",
      " 'It',\n",
      " 'was',\n",
      " 'phenomenal',\n",
      " 'and',\n",
      " 'simply',\n",
      " 'the',\n",
      " 'best',\n",
      " 'I',\n",
      " \"'ve\",\n",
      " 'ever',\n",
      " 'had',\n",
      " '.',\n",
      " 'I',\n",
      " \"'m\",\n",
      " 'pretty',\n",
      " 'sure',\n",
      " 'they',\n",
      " 'only',\n",
      " 'use',\n",
      " 'ingredients',\n",
      " 'from',\n",
      " 'their',\n",
      " 'garden',\n",
      " 'and',\n",
      " 'blend',\n",
      " 'them',\n",
      " 'fresh',\n",
      " 'when',\n",
      " 'you',\n",
      " 'order',\n",
      " 'it',\n",
      " '.',\n",
      " 'It',\n",
      " 'was',\n",
      " 'amazing',\n",
      " '.',\n",
      " 'While',\n",
      " 'EVERYTHING',\n",
      " 'on',\n",
      " 'the',\n",
      " 'menu',\n",
      " 'looks',\n",
      " 'excellent',\n",
      " ',',\n",
      " 'I',\n",
      " 'had',\n",
      " 'the',\n",
      " 'white',\n",
      " 'truffle',\n",
      " 'scrambled',\n",
      " 'eggs',\n",
      " 'vegetable',\n",
      " 'skillet',\n",
      " 'and',\n",
      " 'it',\n",
      " 'was',\n",
      " 'tasty',\n",
      " 'and',\n",
      " 'delicious',\n",
      " '.',\n",
      " 'It',\n",
      " 'came',\n",
      " 'with',\n",
      " '2',\n",
      " 'pieces',\n",
      " 'of',\n",
      " 'their',\n",
      " 'griddled',\n",
      " 'bread',\n",
      " 'with',\n",
      " 'was',\n",
      " 'amazing',\n",
      " 'and',\n",
      " 'it',\n",
      " 'absolutely',\n",
      " 'made',\n",
      " 'the',\n",
      " 'meal',\n",
      " 'complete',\n",
      " '.',\n",
      " 'It',\n",
      " 'was',\n",
      " 'the',\n",
      " 'best',\n",
      " '``',\n",
      " 'toast',\n",
      " \"''\",\n",
      " 'I',\n",
      " \"'ve\",\n",
      " 'ever',\n",
      " 'had',\n",
      " '.',\n",
      " 'Anyway',\n",
      " ',',\n",
      " 'I',\n",
      " 'ca',\n",
      " \"n't\",\n",
      " 'wait',\n",
      " 'to',\n",
      " 'go',\n",
      " 'back',\n",
      " '!']\n"
     ]
    }
   ],
   "source": [
    "# tokenize a review with nltk into word tokens\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "review = data[0]['text']\n",
    "tokens = word_tokenize(review)\n",
    "\n",
    "pprint(review)\n",
    "print()\n",
    "print('Number of tokens: ', len(tokens))\n",
    "pprint(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('My wife took me here on my birthday for breakfast and it was excellent.  The '\n",
      " 'weather was perfect which made sitting outside overlooking their grounds an '\n",
      " 'absolute pleasure.  Our waitress was excellent and our food arrived quickly '\n",
      " 'on the semi-busy Saturday morning.  It looked like the place fills up pretty '\n",
      " 'quickly so the earlier you get here the better.\\n'\n",
      " '\\n'\n",
      " 'Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply '\n",
      " \"the best I've ever had.  I'm pretty sure they only use ingredients from \"\n",
      " 'their garden and blend them fresh when you order it.  It was amazing.\\n'\n",
      " '\\n'\n",
      " 'While EVERYTHING on the menu looks excellent, I had the white truffle '\n",
      " 'scrambled eggs vegetable skillet and it was tasty and delicious.  It came '\n",
      " 'with 2 pieces of their griddled bread with was amazing and it absolutely '\n",
      " 'made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n'\n",
      " '\\n'\n",
      " \"Anyway, I can't wait to go back!\")\n",
      "\n",
      "Number of sentences:  12\n",
      "['My', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', 'was', 'excellent', '.']\n",
      "['The', 'weather', 'was', 'perfect', 'which', 'made', 'sitting', 'outside', 'overlooking', 'their', 'grounds', 'an', 'absolute', 'pleasure', '.']\n",
      "['Our', 'waitress', 'was', 'excellent', 'and', 'our', 'food', 'arrived', 'quickly', 'on', 'the', 'semi-busy', 'Saturday', 'morning', '.']\n",
      "['It', 'looked', 'like', 'the', 'place', 'fills', 'up', 'pretty', 'quickly', 'so', 'the', 'earlier', 'you', 'get', 'here', 'the', 'better', '.']\n",
      "['Do', 'yourself', 'a', 'favor', 'and', 'get', 'their', 'Bloody', 'Mary', '.']\n",
      "['It', 'was', 'phenomenal', 'and', 'simply', 'the', 'best', 'I', \"'ve\", 'ever', 'had', '.']\n",
      "['I', \"'m\", 'pretty', 'sure', 'they', 'only', 'use', 'ingredients', 'from', 'their', 'garden', 'and', 'blend', 'them', 'fresh', 'when', 'you', 'order', 'it', '.']\n",
      "['It', 'was', 'amazing', '.']\n",
      "['While', 'EVERYTHING', 'on', 'the', 'menu', 'looks', 'excellent', ',', 'I', 'had', 'the', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'and', 'it', 'was', 'tasty', 'and', 'delicious', '.']\n",
      "['It', 'came', 'with', '2', 'pieces', 'of', 'their', 'griddled', 'bread', 'with', 'was', 'amazing', 'and', 'it', 'absolutely', 'made', 'the', 'meal', 'complete', '.']\n",
      "['It', 'was', 'the', 'best', '``', 'toast', \"''\", 'I', \"'ve\", 'ever', 'had', '.']\n",
      "['Anyway', ',', 'I', 'ca', \"n't\", 'wait', 'to', 'go', 'back', '!']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize into sentences (also called sentencizing)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "review = data[0]['text']\n",
    "sentences = [word_tokenize(s) for s in sent_tokenize(review)]\n",
    "\n",
    "pprint(review)\n",
    "print()\n",
    "print('Number of sentences: ', len(sentences))\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences only (no word tokens):\n",
      "My wife took me here on my birthday for breakfast and it was excellent.\n",
      "The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.\n",
      "Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.\n",
      "It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "Do yourself a favor and get their Bloody Mary.\n",
      "It was phenomenal and simply the best I've ever had.\n",
      "I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.\n",
      "It was amazing.\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.\n",
      "It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.\n",
      "It was the best \"toast\" I've ever had.\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "# note that sentences are tokenized further into words in the previous example\n",
    "# if you only want sentences, you can do this instead:\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "review = data[0]['text']\n",
    "\n",
    "sentences = sent_tokenize(review)\n",
    "print('Sentences only (no word tokens):')\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common tokens:\n",
      "[('.', 11),\n",
      " ('the', 9),\n",
      " ('and', 8),\n",
      " ('was', 8),\n",
      " ('It', 5),\n",
      " ('I', 5),\n",
      " ('it', 4),\n",
      " ('their', 4),\n",
      " ('on', 3),\n",
      " ('excellent', 3)]\n",
      "\n",
      "Ten least common tokens:\n",
      "[('toast', 1),\n",
      " (\"''\", 1),\n",
      " ('Anyway', 1),\n",
      " ('ca', 1),\n",
      " (\"n't\", 1),\n",
      " ('wait', 1),\n",
      " ('to', 1),\n",
      " ('go', 1),\n",
      " ('back', 1),\n",
      " ('!', 1)]\n"
     ]
    }
   ],
   "source": [
    "# count tokens in review\n",
    "from collections import Counter\n",
    "\n",
    "review = data[0]['text']\n",
    "tokens = word_tokenize(review)\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "# Ten most common tokens\n",
    "print('Ten most common tokens and counts:')\n",
    "pprint(token_counts.most_common(10))\n",
    "print()\n",
    "\n",
    "# Ten least common tokens\n",
    "print('Ten least common tokens and counts:')\n",
    "pprint(token_counts.most_common()[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My => my\n",
      "wife => wife\n",
      "took => took\n",
      "me => me\n",
      "here => here\n",
      "on => on\n",
      "my => my\n",
      "birthday => birthday\n",
      "for => for\n",
      "breakfast => breakfast\n",
      "and => and\n",
      "it => it\n",
      "was => wa\n",
      "excellent => excel\n",
      ". => .\n",
      "The => the\n",
      "weather => weather\n",
      "was => wa\n",
      "perfect => perfect\n",
      "which => which\n",
      "made => made\n",
      "sitting => sit\n",
      "outside => outsid\n",
      "overlooking => overlook\n",
      "their => their\n",
      "grounds => ground\n",
      "an => an\n",
      "absolute => absolut\n",
      "pleasure => pleasur\n",
      ". => .\n",
      "Our => our\n",
      "waitress => waitress\n",
      "was => wa\n",
      "excellent => excel\n",
      "and => and\n",
      "our => our\n",
      "food => food\n",
      "arrived => arriv\n",
      "quickly => quickli\n",
      "on => on\n",
      "the => the\n",
      "semi-busy => semi-busi\n",
      "Saturday => saturday\n",
      "morning => morn\n",
      ". => .\n",
      "It => it\n",
      "looked => look\n",
      "like => like\n",
      "the => the\n",
      "place => place\n",
      "fills => fill\n",
      "up => up\n",
      "pretty => pretti\n",
      "quickly => quickli\n",
      "so => so\n",
      "the => the\n",
      "earlier => earlier\n",
      "you => you\n",
      "get => get\n",
      "here => here\n",
      "the => the\n",
      "better => better\n",
      ". => .\n",
      "Do => do\n",
      "yourself => yourself\n",
      "a => a\n",
      "favor => favor\n",
      "and => and\n",
      "get => get\n",
      "their => their\n",
      "Bloody => bloodi\n",
      "Mary => mari\n",
      ". => .\n",
      "It => it\n",
      "was => wa\n",
      "phenomenal => phenomen\n",
      "and => and\n",
      "simply => simpli\n",
      "the => the\n",
      "best => best\n",
      "I => i\n",
      "'ve => 've\n",
      "ever => ever\n",
      "had => had\n",
      ". => .\n",
      "I => i\n",
      "'m => 'm\n",
      "pretty => pretti\n",
      "sure => sure\n",
      "they => they\n",
      "only => onli\n",
      "use => use\n",
      "ingredients => ingredi\n",
      "from => from\n",
      "their => their\n",
      "garden => garden\n",
      "and => and\n",
      "blend => blend\n",
      "them => them\n",
      "fresh => fresh\n",
      "when => when\n",
      "you => you\n",
      "order => order\n",
      "it => it\n",
      ". => .\n",
      "It => it\n",
      "was => wa\n",
      "amazing => amaz\n",
      ". => .\n",
      "While => while\n",
      "EVERYTHING => everyth\n",
      "on => on\n",
      "the => the\n",
      "menu => menu\n",
      "looks => look\n",
      "excellent => excel\n",
      ", => ,\n",
      "I => i\n",
      "had => had\n",
      "the => the\n",
      "white => white\n",
      "truffle => truffl\n",
      "scrambled => scrambl\n",
      "eggs => egg\n",
      "vegetable => veget\n",
      "skillet => skillet\n",
      "and => and\n",
      "it => it\n",
      "was => wa\n",
      "tasty => tasti\n",
      "and => and\n",
      "delicious => delici\n",
      ". => .\n",
      "It => it\n",
      "came => came\n",
      "with => with\n",
      "2 => 2\n",
      "pieces => piec\n",
      "of => of\n",
      "their => their\n",
      "griddled => griddl\n",
      "bread => bread\n",
      "with => with\n",
      "was => wa\n",
      "amazing => amaz\n",
      "and => and\n",
      "it => it\n",
      "absolutely => absolut\n",
      "made => made\n",
      "the => the\n",
      "meal => meal\n",
      "complete => complet\n",
      ". => .\n",
      "It => it\n",
      "was => wa\n",
      "the => the\n",
      "best => best\n",
      "`` => ``\n",
      "toast => toast\n",
      "'' => ''\n",
      "I => i\n",
      "'ve => 've\n",
      "ever => ever\n",
      "had => had\n",
      ". => .\n",
      "Anyway => anyway\n",
      ", => ,\n",
      "I => i\n",
      "ca => ca\n",
      "n't => n't\n",
      "wait => wait\n",
      "to => to\n",
      "go => go\n",
      "back => back\n",
      "! => !\n"
     ]
    }
   ],
   "source": [
    "# stem tokens in review\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "review = data[0]['text']\n",
    "tokens = word_tokenize(review)\n",
    "stemmed_tokens = [ps.stem(t) for t in tokens]\n",
    "\n",
    "for tok in tokens:\n",
    "    print(tok, '=>', ps.stem(tok))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
